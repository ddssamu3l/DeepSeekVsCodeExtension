# LoCopilot - Locally-Running AI Coding Helper
- This is a AI coding agent Vs Code extension powered by Ollama's latest open-source models
- The coding agent has full context of the user's opened files and selected texts.

## <a href="https://youtu.be/0bjnZnhsjqo">YouTube Demo</a>


  
## Getting Started
Install Ollama from the download link: <a href="https://ollama.com/download">https://ollama.com/download</a>

Alternitively, install it manually
```
curl -fsSL https://ollama.com/install.sh | sh
```

## Next Steps
After installing Ollama, be sure to install at least 1 model before running the extension.

Select from one of the available models (brackets indicate VRAM usage)
- DeepSeek R1 8b   (4.9GB)
- DeepSeek R1 70b  (43GB)
- Gemma 3 4b (3.3GB)
- Gemma 3 27b (17GB)
- QwQ (20GB)

### Example (default model: DeepSeek R1 8b)
```
ollama pull deepseek-r1:8b
```

## Support
For any issues with the extension, reach out to us directly at samueldeng78@gmail.com
